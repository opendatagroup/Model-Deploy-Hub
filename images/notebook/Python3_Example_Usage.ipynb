{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries, and define our schemata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastscore import ipmagic\n",
    "import pandas as pd\n",
    "\n",
    "sch_in = '{\"type\":\"record\", \"name\":\"xy\", \"fields\":[{\"name\":\"x\", \"type\":\"double\"}, {\"name\":\"y\", \"type\":\"double\"}]}'\n",
    "sch_out = '{\"type\":\"record\", \"name\":\"xyz\", \"fields\":[{\"name\":\"x\", \"type\":\"double\"}, {\"name\":\"y\", \"type\":\"double\"}, {\"name\":\"z\", \"type\":\"double\"}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can create \"attachments\"---external files used by the model. Here, we just pickle an object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_params = {'a': 1, 'b': 2}\n",
    "pickle.dump(model_params, open('model_params.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Use the `py3model` cell magic to define a model (Python notebooks only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%py3model\n",
    " \n",
    "# fastscore.input: sch_in\n",
    "# fastscore.output: sch_out\n",
    "# fastscore.recordsets: none\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    " \n",
    "def begin():\n",
    "    global model_params\n",
    "    model_params = pickle.load(open('model_params.pkl', 'rb'))\n",
    " \n",
    "def action(datum):\n",
    "    mydf = datum\n",
    "    mydf['z'] = model_params['a']*mydf['x'] + model_params['b']*mydf['y']\n",
    "    # yield dict(mydf.sum()) # recordset input, regular output\n",
    "    yield mydf # recordsets input and output\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score with JSON serialization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model.score(['{\"x\":1.0, \"y\":2.0}'], use_json = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or without JSON serialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model.score([{\"x\":1.0, \"y\":2.0}], use_json = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model validation tests that inputs and desired outputs conform to schema, and then compares scores generated to the expected results. JSON serialization of inputs and outputs is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model.validate(['{\"x\":1.0, \"y\":2.0}'], ['{\"y\": 2.0, \"x\": 1.0, \"z\": 3.0}'], use_json = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record sets are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use dataframes\n",
    "_model.options['recordsets'] = 'both' # switch to using record sets\n",
    "\n",
    "# create a DataFrame\n",
    "mydf = pd.DataFrame({'x':[1.0, 2.0, 3.0], 'y':[4.0, 5.0, 6.0]})\n",
    "_model.score(mydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or, use JSON-serialized inputs\n",
    "from fastscore.codec import to_json\n",
    "\n",
    "inputs = [x for x in to_json(mydf, _model.input_schema)]\n",
    "_model.score(inputs, use_json = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebind the model's `action` method or other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action(datum):\n",
    "    datum['z'] = model_params['a']*datum['x'] - model_params['b']*datum['y']\n",
    "    yield datum\n",
    "\n",
    "_model.action = action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what the model will look like by exporting to a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_model.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the attachment we created. You can bundle multiple external files into a single attachment. FastScore expects an attachment to be either a gzipped tarball (.tar.gz) or just a .zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open('attachment.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('model_params.pkl')\n",
    "\n",
    "_model.attachments.append('attachment.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastScore Engines\n",
    "\n",
    "The Engine class lets you interact directly with a running engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we connect to a running FastScore engine:\n",
    "import os\n",
    "ENGINE_ADDRESS = os.environ['ENGINE_ADDRESS']\n",
    "from fastscore import Engine\n",
    "engine = Engine(ENGINE_ADDRESS, container='engine-x-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model` objects can be deployed directly to an `Engine`. (Check the FastScore Dashboard!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give our model a name, and deploy it.\n",
    "_model.name = 'example_py3_model'\n",
    "engine.deploy(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic JSON serialization lets you pass Python objects directly to a running `Engine` for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score using either Python objects (in this case, a DataFrame)\n",
    "engine.score(mydf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the `Engine` when you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
